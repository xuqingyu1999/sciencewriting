# -*- coding: utf-8 -*-
import os
import json
import time
import re
import requests
import pandas as pd
import streamlit as st
from io import StringIO
from dataclasses import dataclass, field
from typing import List, Dict, Any, Optional
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity

# ===== å¯é€‰æ›´å¼ºå‘é‡æ£€ç´¢ï¼ˆè‡ªåŠ¨é™çº§ï¼‰ =====
_USE_ST = False
try:
    from sentence_transformers import SentenceTransformer
    _USE_ST = True
except Exception:
    _USE_ST = False

# ===== UI æ ·å¼ =====
st.set_page_config(page_title="LLM å­¦æœ¯å†™ä½œæµæ°´çº¿ï¼ˆDeepSeek + RAGï¼‰", page_icon="ğŸ§­", layout="wide")
st.markdown("""
<style>
h1, h2, h3 { font-family: "Segoe UI", "PingFang SC", "Helvetica Neue", Arial; }
.block-container { padding-top: 1.2rem; }
div[data-testid="stSidebar"] { background: linear-gradient(180deg, #0f172a 0%, #111827 100%); }
div[data-testid="stSidebar"] * { color: #f3f4f6; }
.kpi { background: #0ea5e910; border: 1px solid #0ea5e933; padding: 12px 14px; border-radius: 16px; }
.codebox { background: #111827; color: #e5e7eb; padding: 12px 14px; border-radius: 12px; font-size: 13px; border: 1px solid #374151; }
hr{ border: none; border-top: 1px dashed #d1d5db44; margin: 0.8rem 0;}
.tag { display:inline-block; padding:2px 8px; border-radius:999px; background:#111827; color:#a7f3d0; border:1px solid #065f46; margin-right:6px; font-size:12px;}
</style>
""", unsafe_allow_html=True)

# ===== å·¥å…·å‡½æ•° =====
def truncate_text(s: str, max_chars: int = 12000) -> str:
    if s is None: return ""
    return s if len(s) <= max_chars else s[:max_chars] + "\n...[TRUNCATED]..."

def extract_json_block(text: str) -> Optional[dict]:
    """å°½åŠ›ä»æ¨¡å‹è¾“å‡ºä¸­æå– JSON"""
    if not text: return None
    try:
        return json.loads(text)
    except Exception:
        pass
    m = re.search(r'\{.*\}$', text.strip(), re.S)
    if m:
        try:
            return json.loads(m.group(0))
        except Exception:
            return None
    m = re.search(r'\{.*\}', text, re.S)
    if m:
        try:
            return json.loads(m.group(0))
        except Exception:
            return None
    return None

def looks_like_meta(text: str) -> bool:
    """åˆ¤æ–­æ˜¯å¦åƒå…ƒæè¿°è€Œéæ­£æ–‡"""
    if not text: return True
    bad_keywords = ["å°†ä¼š", "å°†è¦", "ä¼šé€šè¿‡", "will ", "revised draft will", "we will", "we plan to"]
    return any(k.lower() in text.lower() for k in bad_keywords) or len(text) < 300

# ===== LLM å®¢æˆ·ç«¯ =====
class LLMClient:
    def __init__(self, api_key: str, base_url: str = "https://api.deepseek.com", model: str = "deepseek-chat", timeout: int = 120):
        self.api_key = api_key
        self.base_url = base_url.rstrip("/")
        self.model = model
        self.timeout = timeout

    def chat(self, messages: List[Dict[str, str]], temperature: float = 0.2,
             max_tokens: Optional[int] = None, response_format: Optional[dict] = None) -> str:
        url = f"{self.base_url}/v1/chat/completions"
        headers = {"Authorization": f"Bearer {self.api_key}", "Content-Type": "application/json"}
        payload = {"model": self.model, "messages": messages, "temperature": temperature}
        if max_tokens is not None: payload["max_tokens"] = max_tokens
        if response_format is not None: payload["response_format"] = response_format
        resp = requests.post(url, headers=headers, json=payload, timeout=self.timeout)
        if resp.status_code != 200:
            raise RuntimeError(f"LLM APIé”™è¯¯[{resp.status_code}]: {resp.text}")
        data = resp.json()
        try:
            return data["choices"][0]["message"]["content"]
        except Exception:
            raise RuntimeError(f"æ— æ³•è§£æLLMè¿”å›ï¼š{data}")

    def chat_json(self, messages: List[Dict[str,str]], temperature: float = 0.2,
                  max_tokens: Optional[int]=None, required_keys: Optional[List[str]]=None, retries:int=2) -> dict:
        """ä¼˜å…ˆ JSON æ¨¡å¼ï¼›å¤±è´¥åˆ™äºŒæ¬¡æç¤ºåªè¿”å› JSONï¼›æœ€åå›é€€æ­£åˆ™æŠ½å–"""
        # å°è¯• 1ï¼šJSON æ¨¡å¼
        out = self.chat(messages, temperature=temperature, max_tokens=max_tokens,
                        response_format={"type":"json_object"})
        j = extract_json_block(out)
        if j and (not required_keys or all(k in j for k in required_keys)):
            return j
        # å°è¯• 2ï¼šåŠ ä¸€æ¡ç³»ç»Ÿæç¤ºï¼Œå¼ºåˆ¶æœ€å° JSON
        forced = [{"role":"system","content":"è¯·åªè¿”å›ä¸¥æ ¼åˆæ³•çš„æœ€å°åŒ– JSONï¼Œä¸å¾—åŒ…å«ä»»ä½•é¢å¤–æ–‡å­—æˆ–è§£é‡Šã€‚"},
                  *messages]
        out2 = self.chat(forced, temperature=temperature, max_tokens=max_tokens,
                         response_format={"type":"json_object"})
        j2 = extract_json_block(out2)
        if j2 and (not required_keys or all(k in j2 for k in required_keys)):
            return j2
        # å°è¯• 3ï¼šæ™®é€šæ¨¡å¼ + æ­£åˆ™æŠ½å–
        out3 = self.chat(messages, temperature=temperature, max_tokens=max_tokens)
        j3 = extract_json_block(out3) or {}
        return j3

# ===== RAG æ£€ç´¢ =====
class RAGRetriever:
    def __init__(self, df: pd.DataFrame, use_sentence_transformer: bool = _USE_ST, st_model: str = "all-MiniLM-L6-v2"):
        assert "title" in df.columns and "text" in df.columns, "xlsx éœ€è¦åŒ…å« 'title' å’Œ 'text' åˆ—"
        self.df = df.reset_index(drop=True).copy()
        self.use_st = use_sentence_transformer
        self._vectorizer = None
        self._tfidf_matrix = None
        self._embedder = None
        self._embeddings = None
        self.st_model_name = st_model

    @st.cache_data(show_spinner=False)
    def _build_tfidf(_self, corpus: List[str]):
        vec = TfidfVectorizer(stop_words="english", max_features=200000)
        mat = vec.fit_transform(corpus)
        return vec, mat

    def _ensure_index(self):
        corpus = (self.df["title"].astype(str) + " " + self.df["text"].astype(str)).tolist()
        if self.use_st:
            if self._embedder is None:
                self._embedder = SentenceTransformer(self.st_model_name)
                self._embeddings = self._embedder.encode(corpus, convert_to_numpy=True, show_progress_bar=False)
        else:
            if self._vectorizer is None or self._tfidf_matrix is None:
                self._vectorizer, self._tfidf_matrix = self._build_tfidf(corpus)

    def search(self, query: str, top_k: int = 10) -> pd.DataFrame:
        self._ensure_index()
        if self.use_st:
            qv = self._embedder.encode([query], convert_to_numpy=True)
            sim = (self._embeddings @ qv.T).reshape(-1)
        else:
            qv = self._vectorizer.transform([query])
            sim = cosine_similarity(qv, self._tfidf_matrix).flatten()
        idx = sim.argsort()[-top_k:][::-1]
        out = self.df.iloc[idx].copy()
        out["score"] = sim[idx]
        out["doc_id"] = out.index.astype(str)
        return out[["doc_id","title","text","score"]]

# ===== äº§ç‰©å­˜å‚¨ =====
@dataclass
class PipelineArtifacts:
    plan_json: Dict[str, Any] = field(default_factory=dict)
    retrieved: pd.DataFrame = field(default_factory=lambda: pd.DataFrame(columns=["doc_id","title","text","score"]))
    outline_json: Dict[str, Any] = field(default_factory=dict)
    title: str = ""
    drafts: Dict[str, str] = field(default_factory=dict)
    verified: Dict[str, Any] = field(default_factory=dict)
    refined: str = ""
    evaluation: Dict[str, Any] = field(default_factory=dict)
    abstract: str = ""
    full_paper_md: str = ""

# ===== Prompt æ¨¡æ¿ï¼ˆå†…ç½®â€œä¿¡æºä¼˜å…ˆçº§â€ï¼‰ =====
def source_of_truth_block(user_need: str) -> str:
    return f"""
ã€ä¿¡æºä¼˜å…ˆçº§ã€‘ï¼š
1) ç”¨æˆ·éœ€æ±‚æ–‡æœ¬ï¼ˆæœ€é«˜ä¼˜å…ˆçº§ï¼‰ï¼š{user_need}
2) RAG/HyDE æ–‡æ¡£ï¼ˆä»…ä½œè¾…åŠ©ï¼›å¦‚ä¸éœ€æ±‚å†²çªï¼Œå¿…é¡»ä»¥éœ€æ±‚ä¸ºå‡†ï¼‰
3) è¯æ®ä¸è¶³æ—¶ï¼šè¾“å‡º NEED MORE EVIDENCE: <å»ºè®®æ£€ç´¢æŸ¥è¯¢>ï¼Œè€Œä¸æ˜¯è‡†æµ‹
"""

def prompt_plan(keywords: str, requirements: str, hyde_summary: str, user_need: str) -> List[Dict[str,str]]:
    user_prompt = f"""{source_of_truth_block(user_need)}
ä½ æ˜¯ä¸€ä½å­¦æœ¯å†™ä½œè§„åˆ’å¸ˆã€‚å·²çŸ¥ï¼š
å…³é”®è¯ï¼š{keywords}
éœ€æ±‚çº¦æŸï¼š{requirements}
HyDEæ‘˜è¦ï¼š{hyde_summary}

è¯·è¾“å‡º 3â€“7 æ­¥å†™ä½œè®¡åˆ’ï¼ˆä¸¥æ ¼ JSONï¼‰ï¼š
{{"plan":[{{"step":1,"objective":"","artifact":""}}], "open_questions":[]}}
"""
    return [{"role":"user","content":user_prompt}]

def prompt_outline(venue_style: str, research_need: str, evidence_pack: str, user_need: str) -> List[Dict[str,str]]:
    user_prompt = f"""{source_of_truth_block(user_need)}
ä½ æ˜¯ä¸€ä½å­¦æœ¯å†™ä½œä¸“å®¶ï¼ˆ{venue_style} é£æ ¼ï¼‰ã€‚ä»»åŠ¡ï¼š
1) ç”Ÿæˆä¸€æ¡è®ºæ–‡æ ‡é¢˜
2) ç”Ÿæˆ IMRaD å¤§çº²ï¼ˆä¸¥æ ¼ JSONï¼‰ï¼š
{{
  "title": "",
  "outline": {{
    "Introduction": [],
    "Methods": [],
    "Results": [],
    "Discussion": []
  }}
}}
è¦æ±‚ï¼š
- ä¼˜å…ˆæ»¡è¶³ç”¨æˆ·éœ€æ±‚ï¼›RAG/HyDE ä»…ä½œè¾…åŠ©
- æ¯é¡¹è¦ç‚¹ 10 å­—ä»¥å†…å…³é”®è¯ï¼›ä¸å¾—æ·»åŠ é¢å¤–å­—æ®µ
å‚è€ƒè¯æ®ï¼ˆå¯é€‰ï¼‰ï¼š 
{evidence_pack}
"""
    return [{"role":"user","content":user_prompt}]

def prompt_title_only(research_need: str, user_need: str) -> List[Dict[str,str]]:
    return [{"role":"user","content":f"""{source_of_truth_block(user_need)}
è¯·åŸºäºç”¨æˆ·éœ€æ±‚ç”Ÿæˆ 1 ä¸ªé¡¶åˆŠé£æ ¼æ ‡é¢˜ã€‚åªè¾“å‡ºæ ‡é¢˜æ–‡æœ¬ï¼Œä¸è¦å‰åç¼€æˆ–è§£é‡Šã€‚
éœ€æ±‚ï¼š{research_need}
"""}]

def prompt_expand(section_name: str, points: List[str], evidence_pack: str, venue_style: str, user_need: str) -> List[Dict[str,str]]:
    pts = "\n- " + "\n- ".join(points) if points else ""
    user_prompt = f"""{source_of_truth_block(user_need)}
è¯·æ‰©å†™ã€Š{section_name}ã€‹éƒ¨åˆ†ï¼Œå‚è€ƒè¦ç‚¹ï¼š{pts}

è¯æ®ï¼ˆä»…å¯å¼•ç”¨å…¶ä¸­å†…å®¹ï¼›ä¸å¾—æœæ’°ï¼‰ï¼š
{evidence_pack}

å†™ä½œè¦æ±‚ï¼š
- é£æ ¼ï¼š{venue_style} é¡¶åˆŠé£æ ¼ï¼ˆä¸¥è°¨ã€å®¢è§‚ã€å¯æ£€éªŒï¼‰
- ç»“æ„ï¼š3â€”5æ®µï¼Œé€»è¾‘æ¸…æ¥šï¼Œä¸è·‘é¢˜
- å¦‚è¯æ®ä¸è¶³ï¼šè¾“å‡º NEED MORE EVIDENCE: <æŸ¥è¯¢>
"""
    return [{"role":"user","content":user_prompt}]

def prompt_verify(draft: str, evidence_pack: str, user_need: str) -> List[Dict[str,str]]:
    user_prompt = f"""{source_of_truth_block(user_need)}
å¯¹ä»¥ä¸‹è‰ç¨¿æ‰§è¡Œ Chain-of-Verificationï¼ˆä¸¥æ ¼ JSONï¼‰ï¼š
è‰ç¨¿ï¼š
{draft}

è¯æ®ï¼ˆä»…æ­¤ä¸ºå‡†ï¼‰ï¼š
{evidence_pack}

è¾“å‡ºï¼š
{{
  "verification_questions": [],
  "qa_log": [{{"q":"","a":""}}],
  "revised_draft": ""
}}
è§„åˆ™ï¼š
- ä»…å¯¹è¯æ®ä¸è¶³ä¹‹å¤„åšæœ€å°ä¿®æ”¹
- å¼•ç”¨ä½¿ç”¨ [doc_id]
"""
    return [{"role":"user","content":user_prompt}]

def prompt_refine(draft: str, venue_style: str, user_need: str) -> List[Dict[str,str]]:
    user_prompt = f"""{source_of_truth_block(user_need)}
è§’è‰²Aï¼ˆå®¡ç¨¿äººï¼‰ï¼šç»™å‡º strengths / weaknesses / must_fixesï¼ˆæ¸…æ™°åº¦ã€è¿è´¯æ€§ã€è®ºè¯ä¸¥è°¨æ€§ã€å¼•ç”¨åˆè§„ã€{venue_style} é£æ ¼ï¼‰
è§’è‰²Bï¼ˆä½œè€…ï¼‰ï¼šå…ˆè½å® must_fixesï¼Œå†å¤„ç† weaknessesï¼Œä¿æŒå¼•ç”¨ä¸å˜ã€‚
æœ€ç»ˆåªè¿”å›ä¸¥æ ¼ JSONï¼Œä¸” "revised" å¿…é¡»æ˜¯**ä¿®è®¢åçš„å®Œæ•´æ­£æ–‡**ï¼Œä¸å¾—å†™è®¡åˆ’æˆ–æ„å›¾ã€‚

{{
  "review": {{"strengths":[],"weaknesses":[],"must_fixes":[]}},
  "revised": ""
}}
è‰ç¨¿ï¼š
{draft}
"""
    return [{"role":"user","content":user_prompt}]

def prompt_force_rewrite(draft: str, user_need: str) -> List[Dict[str,str]]:
    return [{"role":"user","content":f"""{source_of_truth_block(user_need)}
è¯·ç›´æ¥è¾“å‡ºä¿®è®¢åçš„å®Œæ•´æ­£æ–‡ï¼ˆè¦†ç›–åŸæ–‡æ‰€æœ‰éƒ¨åˆ†ï¼‰ï¼Œä¸è¦å†™è®¡åˆ’æˆ–æ„å›¾ï¼Œä¸è¦ä½¿ç”¨å°†æ¥æ—¶æè¿°ã€‚
ä¿æŒå¼•ç”¨æ ‡æ³¨ä¸å˜ã€‚
åŸç¨¿ï¼š
{draft}
"""}]

def prompt_evaluate(draft: str, venue_style: str, user_need: str) -> List[Dict[str,str]]:
    user_prompt = f"""{source_of_truth_block(user_need)}
è¯·æŒ‰ 0-5 è¯„åˆ†å¹¶ç®€è¿°ç†ç”±ï¼ˆä¸¥æ ¼ JSONï¼‰ï¼š
{{"clarity":0,"rigor":0,"style":0,"structure_citation":0,"comments":""}}
ç»´åº¦ï¼šæ¸…æ™°åº¦ clarityï¼›ä¸¥è°¨æ€§ rigorï¼›{venue_style} é£æ ¼ styleï¼›ç»“æ„ä¸å¼•ç”¨å®Œæ•´æ€§ structure_citation
æ–‡æœ¬ï¼š
{draft}
"""
    return [{"role":"user","content":user_prompt}]

def prompt_abstract(full_text: str, user_need: str) -> List[Dict[str,str]]:
    user_prompt = f"""{source_of_truth_block(user_need)}
åŸºäºè®ºæ–‡æ­£æ–‡ï¼ˆå¯æ‹©è¦ï¼‰ï¼Œä½¿ç”¨ Chain-of-Density æ‰“ç£¨æ‘˜è¦ã€‚
è¦æ±‚ï¼š**ä»¥ç”¨æˆ·éœ€æ±‚ä¸ºå”¯ä¸€ä¼˜å…ˆä¿¡æº**ï¼ŒRAG/HyDE ä»…ä½œè¾…åŠ©ï¼›ä¸å¾—å¼•å…¥ä¸å­˜åœ¨äºéœ€æ±‚/æ­£æ–‡çš„ä¸»å¼ ã€‚
è¾“å‡ºä¸‰éƒ¨åˆ†ï¼š
1) ç®€æ´æ‘˜è¦ï¼ˆ~130å­—ï¼Œå®ä½“ç¨€ç–ï¼‰
2) ç¼ºå¤±çš„é‡è¦å®ä½“åˆ—è¡¨
3) åœ¨ä¸å¢åŠ é•¿åº¦æƒ…å†µä¸‹é‡å†™çš„æ‘˜è¦ï¼ˆè¡¥é½å®ä½“ï¼‰
æ­£æ–‡ï¼š
{full_text}
"""
    return [{"role":"user","content":user_prompt}]

# ===== ä¾§è¾¹æ é…ç½® =====
with st.sidebar:
    st.title("âš™ï¸ é…ç½®")
    api_key = st.text_input("DeepSeek API Key", value=os.getenv("DEEPSEEK_API_KEY",""), type="password")
    base_url = st.text_input("Base URL", value=os.getenv("DEEPSEEK_BASE_URL","https://api.deepseek.com"))
    model_name = st.text_input("Model åç§°", value="deepseek-chat")
    venue_style = st.selectbox("ç›®æ ‡æœŸåˆŠé£æ ¼", ["MIS Quarterly (MISQ)", "Information Systems Research (ISR)", "Management Science", "POMS"], index=0)
    top_k = st.slider("RAG Top-K", min_value=5, max_value=20, value=10, step=1)
    use_st = st.toggle("ä½¿ç”¨å¥å‘é‡ï¼ˆæ›´å‡†ä½†æ›´æ…¢ï¼‰", value=_USE_ST)
    st.caption("â€» æœªå‹¾é€‰æ—¶ä½¿ç”¨ TF-IDF + ä½™å¼¦ç›¸ä¼¼åº¦")

# ===== ä¸»é¡µé¢è¾“å…¥ =====
st.title("ğŸ§­ æœ€å°åŒ– LLM å­¦æœ¯å†™ä½œæµæ°´çº¿ï¼ˆå…³é”®è¯ + HyDE + RAGï¼‰")
st.markdown('<div class="kpi">è¾“å…¥éœ€æ±‚ â†’ è§„åˆ’ â†’ RAG â†’ æ ‡é¢˜+å¤§çº² â†’ æ‰©å†™ â†’ æ ¡éªŒ â†’ ç²¾ä¿® â†’ è¯„ä¼° â†’ æ‘˜è¦</div>', unsafe_allow_html=True)

col1, col2 = st.columns([2,1])
with col1:
    user_keywords = st.text_area("ğŸ” å…³é”®è¯ / ä¸€å¥è¯éœ€æ±‚ï¼ˆæœ€é«˜ä¼˜å…ˆçº§ä¿¡æºï¼‰", height=90, placeholder="ä¾‹å¦‚ï¼šå›¢é˜Ÿè´­ä¹°å¯¹éæŠ˜æ‰£å•†å“çš„æº¢å‡ºæ•ˆåº”ï¼›æˆ–ä¸€æ®µç ”ç©¶éœ€æ±‚æè¿°")
with col2:
    hyde_summary = st.text_area("ğŸ“„ HyDE æ‘˜è¦ï¼ˆå¯é€‰ï¼‰", height=90, placeholder="å¯ä¸ºç©ºï¼›ç”¨äºè¾…åŠ©æ£€ç´¢/å†™ä½œ")
requirements = st.text_input("ğŸ“Œ å…¶ä»–ç¡¬æ€§çº¦æŸï¼ˆå­—æ•°ã€æœŸåˆŠã€é¢†åŸŸã€è¯»è€…å¯¹è±¡ç­‰ï¼‰", "")

def USER_NEED():
    return (user_keywords or "").strip() + ("ï¼›" + requirements if requirements else "")

# ä¸Šä¼ çŸ¥è¯†åº“
st.subheader("ğŸ“š ä¸Šä¼ çŸ¥è¯†åº“ï¼ˆ.xlsxï¼Œå« title / textï¼‰")
kb_file = st.file_uploader("é€‰æ‹© Excel æ–‡ä»¶", type=["xlsx"], accept_multiple_files=False)

def read_kb(file) -> Optional[pd.DataFrame]:
    if file is None: return None
    try:
        df = pd.read_excel(file)
        assert "title" in df.columns and "text" in df.columns
        return df
    except Exception as e:
        st.error(f"è¯»å– Excel å¤±è´¥ï¼š{e}")
        return None

df_kb = read_kb(kb_file)

# åˆå§‹åŒ–çŠ¶æ€
if "artifacts" not in st.session_state:
    st.session_state.artifacts = PipelineArtifacts()

_client = LLMClient(api_key, base_url, model_name) if (api_key and base_url and model_name) else None
_retriever = RAGRetriever(df_kb, use_sentence_transformer=use_st) if df_kb is not None else None

def build_evidence_pack(df_sel: pd.DataFrame, max_chars: int = 12000) -> str:
    chunks = []
    for _, r in df_sel.iterrows():
        block = f"[{r['doc_id']}] {r['title']}\n{truncate_text(str(r['text']), 1500)}"
        chunks.append(block)
    combined = "\n\n".join(chunks)
    return truncate_text(combined, max_chars=max_chars)

# ===== æ­¥éª¤å‡½æ•° =====
def step_plan():
    msgs = prompt_plan(user_keywords, requirements, hyde_summary, USER_NEED())
    plan = _client.chat_json(msgs, temperature=0.2, required_keys=["plan","open_questions"])
    st.session_state.artifacts.plan_json = plan
    return plan

def step_rag():
    q = USER_NEED() or hyde_summary
    docs = _retriever.search(q, top_k=top_k)
    st.session_state.artifacts.retrieved = docs
    return docs

def step_outline():
    ev = build_evidence_pack(st.session_state.artifacts.retrieved)
    msgs = prompt_outline(venue_style, USER_NEED() or requirements, ev, USER_NEED())
    j = _client.chat_json(msgs, temperature=0.1, required_keys=["title","outline"])
    st.session_state.artifacts.outline_json = j or {}
    # æ ‡é¢˜å…œåº•
    title = (j or {}).get("title","").strip()
    if not title:
        title = step_title()  # ç‹¬ç«‹ç”Ÿæˆ
    st.session_state.artifacts.title = title
    return j, ev

def step_title() -> str:
    msgs = prompt_title_only(USER_NEED() or requirements, USER_NEED())
    title = _client.chat([{"role":"system","content":"åªè¾“å‡ºæ ‡é¢˜æ–‡æœ¬ã€‚"},
                          *msgs], temperature=0.2, max_tokens=80).strip().strip('"').strip()
    return title

def step_expand():
    outline = st.session_state.artifacts.outline_json or {}
    ev = build_evidence_pack(st.session_state.artifacts.retrieved)
    drafts = {}
    if "outline" not in outline:
        raise RuntimeError("å°šæœªç”Ÿæˆå¤§çº²æˆ–å¤§çº²æ ¼å¼å¼‚å¸¸ã€‚")
    for sec in ["Introduction","Methods","Results","Discussion"]:
        pts = outline["outline"].get(sec, [])
        msgs = prompt_expand(sec, pts, ev, venue_style, USER_NEED())
        text = _client.chat(msgs, temperature=0.15, max_tokens=1600)
        drafts[sec] = text
    st.session_state.artifacts.drafts = drafts
    return drafts, ev

def step_verify():
    drafts = st.session_state.artifacts.drafts
    merged = ""
    for sec in ["Introduction","Methods","Results","Discussion"]:
        if sec in drafts: merged += f"# {sec}\n{drafts[sec]}\n\n"
    ev = build_evidence_pack(st.session_state.artifacts.retrieved)
    msgs = prompt_verify(merged, ev, USER_NEED())
    ver = _client.chat_json(msgs, temperature=0.1, required_keys=["verification_questions","qa_log","revised_draft"])
    st.session_state.artifacts.verified = ver
    return ver

def step_refine():
    verified = st.session_state.artifacts.verified or {}
    revised = verified.get("revised_draft","").strip()
    base_text = revised if revised else "\n".join([f"# {k}\n{v}" for k,v in st.session_state.artifacts.drafts.items()])
    # å…ˆèµ°â€œè¯„å®¡+ä¿®è®¢â€çš„ JSON æµ
    msgs = prompt_refine(base_text, venue_style, USER_NEED())
    j = _client.chat_json(msgs, temperature=0.1, required_keys=["review","revised"])
    refined = j.get("revised","").strip()
    # å¦‚æœä»æ˜¯å…ƒæè¿°æˆ–å¤ªçŸ­ï¼Œåˆ™å¼ºåˆ¶æ”¹å†™ä¸€æ¬¡
    if looks_like_meta(refined):
        forced = _client.chat(prompt_force_rewrite(base_text, USER_NEED()), temperature=0.1, max_tokens=3500)
        refined = forced.strip()
    st.session_state.artifacts.refined = refined
    return refined, j

def step_evaluate():
    draft = st.session_state.artifacts.refined or "\n".join([f"# {k}\n{v}" for k,v in st.session_state.artifacts.drafts.items()])
    msgs = prompt_evaluate(draft, venue_style, USER_NEED())
    eval_json = _client.chat_json(msgs, temperature=0.0, required_keys=["clarity","rigor","style","structure_citation","comments"])
    st.session_state.artifacts.evaluation = eval_json
    return eval_json

def step_abstract():
    title = st.session_state.artifacts.title or "ï¼ˆå¾…å®šæ ‡é¢˜ï¼‰"
    draft = st.session_state.artifacts.refined or "\n".join([f"# {k}\n{v}" for k,v in st.session_state.artifacts.drafts.items()])
    msgs = prompt_abstract(truncate_text(draft, 9000), USER_NEED())
    abs_out = _client.chat(msgs, temperature=0.2, max_tokens=800)
    st.session_state.artifacts.abstract = abs_out
    md = f"# {title}\n\n{draft}\n\n---\n## Abstract\n\n{abs_out}\n"
    st.session_state.artifacts.full_paper_md = md
    return abs_out, md

# ===== æŒ‰é’®åŒº =====
run_cols = st.columns([1,1,1,1,1,1,1,1,2])
btn_plan    = run_cols[0].button("ğŸ§© è§„åˆ’")
btn_rag     = run_cols[1].button("ğŸ“– æ£€ç´¢")
btn_outline = run_cols[2].button("ğŸ§± å¤§çº²/æ ‡é¢˜")
btn_expand  = run_cols[3].button("âœï¸ æ‰©å†™")
btn_verify  = run_cols[4].button("ğŸ”¬ æ ¡éªŒ")
btn_refine  = run_cols[5].button("ğŸ› ï¸ ç²¾ä¿®")
btn_eval    = run_cols[6].button("ğŸ“Š è¯„ä¼°")
btn_abs     = run_cols[7].button("âœ¨ æ‘˜è¦")
btn_all     = run_cols[8].button("ğŸš€ ä¸€é”®å…¨æµç¨‹")

if not _client:
    st.warning("è¯·åœ¨å·¦ä¾§è¾“å…¥ API Key / Base URL / æ¨¡å‹åã€‚")
if _retriever is None:
    st.info("è¯·ä¸Šä¼ çŸ¥è¯†åº“ Excelã€‚")

def run_all():
    if not _client or _retriever is None:
        st.error("è¯·å…ˆé…ç½® API å’Œä¸Šä¼ çŸ¥è¯†åº“ã€‚")
        return
    with st.spinner("å…¨æµç¨‹æ‰§è¡Œä¸­..."):
        step_plan()
        step_rag()
        step_outline()
        step_expand()
        step_verify()
        step_refine()
        step_evaluate()
        step_abstract()
    st.success("å…¨æµç¨‹å®Œæˆï¼")

if btn_all: run_all()
if btn_plan and _client: st.session_state.artifacts.plan_json = step_plan()
if btn_rag and _retriever is not None: st.session_state.artifacts.retrieved = step_rag()
if btn_outline and _client: st.session_state.artifacts.outline_json, _ = step_outline()
if btn_expand and _client: st.session_state.artifacts.drafts, _ = step_expand()
if btn_verify and _client: st.session_state.artifacts.verified = step_verify()
if btn_refine and _client:
    refined, _ = step_refine()
if btn_eval and _client: st.session_state.artifacts.evaluation = step_evaluate()
if btn_abs and _client: st.session_state.artifacts.abstract, st.session_state.artifacts.full_paper_md = step_abstract()

# ===== å¯è§†åŒ–è¾“å‡ºï¼ˆå¯æŠ˜å ï¼‰ =====
st.subheader("ğŸ”­ è¿‡ç¨‹äº§ç‰©ï¼ˆç‚¹å‡»å±•å¼€/æ”¶èµ·ï¼‰")

with st.expander("ğŸ§© æ­¥éª¤ 2 â€” è§„åˆ’ï¼ˆPlanï¼‰", expanded=False):
    st.json(st.session_state.artifacts.plan_json or {"tips":"å°šæœªç”Ÿæˆ"})

with st.expander("ğŸ“– æ­¥éª¤ 3 â€” RAG æ£€ç´¢ç»“æœ", expanded=False):
    if not st.session_state.artifacts.retrieved.empty:
        st.dataframe(st.session_state.artifacts.retrieved, use_container_width=True)
        st.caption("â†‘ å·²æŒ‰ç›¸ä¼¼åº¦æ’åºï¼›doc_id å¯ç”¨äºå¼•ç”¨ã€‚")
    else:
        st.info("å°šæœªæ£€ç´¢æˆ–æ— ç»“æœ")

with st.expander("ğŸ§± æ­¥éª¤ 4 â€” æ ‡é¢˜ä¸å¤§çº²ï¼ˆIMRaDï¼‰", expanded=False):
    j = st.session_state.artifacts.outline_json
    title = st.session_state.artifacts.title
    if title: st.write("**æ ‡é¢˜**ï¼š", title)
    if j:
        st.json(j.get("outline", {}))
        st.download_button("ä¸‹è½½å¤§çº² JSON", data=json.dumps(j, ensure_ascii=False, indent=2),
                           file_name="outline.json", mime="application/json")
    else:
        st.info("å°šæœªç”Ÿæˆ")

with st.expander("âœï¸ æ­¥éª¤ 5 â€” å„éƒ¨åˆ†æ‰©å†™è‰ç¨¿", expanded=False):
    drafts = st.session_state.artifacts.drafts
    if drafts:
        for sec in ["Introduction","Methods","Results","Discussion"]:
            if sec in drafts:
                st.markdown(f"#### {sec}")
                st.markdown(f"<div class='codebox'>{drafts[sec]}</div>", unsafe_allow_html=True)
        st.download_button("ä¸‹è½½è‰ç¨¿ï¼ˆMDï¼‰",
                           data="\n\n".join([f"# {k}\n{v}" for k,v in drafts.items()]),
                           file_name="draft_sections.md", mime="text/markdown")
    else:
        st.info("å°šæœªæ‰©å†™")

with st.expander("ğŸ”¬ æ­¥éª¤ 6 â€” æ ¡éªŒï¼ˆCoVeï¼‰", expanded=False):
    ver = st.session_state.artifacts.verified
    if ver: st.json(ver)
    else: st.info("å°šæœªæ ¡éªŒ")

with st.expander("ğŸ› ï¸ æ­¥éª¤ 7 â€” ç²¾ä¿®ï¼ˆSelf-Refineï¼‰", expanded=False):
    if st.session_state.artifacts.refined:
        st.markdown(f"<div class='codebox'>{st.session_state.artifacts.refined}</div>", unsafe_allow_html=True)
        st.download_button("ä¸‹è½½ä¿®è®¢ç¨¿ï¼ˆMDï¼‰",
                           data=st.session_state.artifacts.refined,
                           file_name="revised.md", mime="text/markdown")
    else:
        st.info("å°šæœªç²¾ä¿®")

with st.expander("ğŸ“Š æ­¥éª¤ 8 â€” è¯„ä¼°ï¼ˆLLM-as-Judgeï¼‰", expanded=False):
    if st.session_state.artifacts.evaluation:
        st.json(st.session_state.artifacts.evaluation)
    else:
        st.info("å°šæœªè¯„ä¼°")

with st.expander("âœ¨ æ­¥éª¤ 9 â€” æ‘˜è¦æ‰“ç£¨ï¼ˆCoDï¼‰ & å…¨æ–‡åˆæˆ", expanded=True):
    if st.session_state.artifacts.abstract:
        st.markdown("**æ‘˜è¦ç»“æœï¼ˆå«ä¸‰æ­¥ï¼‰**")
        st.markdown(f"<div class='codebox'>{st.session_state.artifacts.abstract}</div>", unsafe_allow_html=True)
        if st.session_state.artifacts.full_paper_md:
            st.download_button("ä¸‹è½½å…¨æ–‡ï¼ˆMarkdownï¼‰",
                               data=st.session_state.artifacts.full_paper_md,
                               file_name="paper_full.md", mime="text/markdown")
    else:
        st.info("å°šæœªç”Ÿæˆæ‘˜è¦")

st.markdown("---")
st.caption("Â© 2025 LLM Pipeline Â· DeepSeek API Â· ä¿¡æºä¼˜å…ˆçº§ï¼šéœ€æ±‚ > RAG/HyDE Â· é¡¶åˆŠé£æ ¼ï¼ˆMISQ/ISR/MS/POMSï¼‰")
